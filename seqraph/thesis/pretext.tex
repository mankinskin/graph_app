\thispagestyle{empty}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Abstract
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\vspace*{\fill}
\begin{center}
\bf{Abstract}
\addcontentsline{toc}{section}{Abstract}
\end{center}

%\selectlanguage{english}

\noindent
Recent advances in natural language modelling, driven by the transformer model, have drastically increased expressive power and raised new awareness to standing challenges and risks associated with employing artificial intelligence at a large scale. Although existing language models exhibit convincing generative abilities, they are generally regarded as black-boxes, are known to generate convincing false information and are difficult to update in a directed manner. In this paper we introduce the context graph model, a natural language model based on the reduced sub-string relation for a given raw text corpus. We build the formal foundation for this model by providing a mathematical definition of the model and describe an algorithm for inducing the context graph structure from raw text examples. With this research we present a concept to induce a reconstructable, updatable and human-readable language model from a raw text corpus.

%\newpage
\vspace*{\fill}

